{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "221ef6a9",
   "metadata": {},
   "source": [
    "## XGB Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11ae3a6",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d262bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "import random\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import f1_score\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import joblib\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d628db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a8032a",
   "metadata": {},
   "source": [
    "- Load the train and test files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5320a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_data.csv\")\n",
    "val_df  = pd.read_csv(\"val_data.csv\")\n",
    "test_df  = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1a75566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:   8000 rows\n",
      " Val :   1000 rows\n",
      " Test:   1000 rows\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {len(train_df):>6} rows\")\n",
    "print(f\" Val : {len(val_df):>6} rows\")\n",
    "print(f\" Test: {len(test_df):>6} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d082f",
   "metadata": {},
   "source": [
    "### TF-IDF - Experiment 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0473b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(train_texts, val_texts):\n",
    "    vec = TfidfVectorizer()        #tokenization and vectorization\n",
    "    X_train = vec.fit_transform(train_texts)\n",
    "    X_val   = vec.transform(val_texts)\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f5fbffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_df[\"text\"].astype(str)\n",
    "val_texts   = val_df[\"text\"].astype(str)\n",
    "y_train     = train_df[\"sentiment_id\"]\n",
    "y_val       = val_df[\"sentiment_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afa874c",
   "metadata": {},
   "source": [
    "- Hyperparameter tuning (TF-IDF and logistic regresssion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9e15a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # TFâ€“IDF hyperparameters\n",
    "    max_df       = trial.suggest_float(\"max_df\", 0.5, 1.0)\n",
    "    min_df       = trial.suggest_int(\"min_df\", 1, 5)\n",
    "    ngram_max    = trial.suggest_int(\"ngram_max\", 1, 2)\n",
    "    max_features = trial.suggest_int(\"max_features\", 1_000, 20_000, step=1_000)\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_df=max_df,\n",
    "        min_df=min_df,\n",
    "        ngram_range=(1, ngram_max),\n",
    "        max_features=max_features\n",
    "    )\n",
    "    X_tr = vectorizer.fit_transform(train_texts)\n",
    "    X_va = vectorizer.transform(val_texts)\n",
    "\n",
    "    # XGB hyperparameters\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 300)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.3)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.6, 1.0)\n",
    "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.6, 1.0)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 0.0, 1.0)\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 0.0, 1.0)\n",
    "\n",
    "    clf = XGBClassifier(\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=3,\n",
    "        eval_metric=\"mlogloss\",\n",
    "        random_state=42,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        reg_alpha=reg_alpha,\n",
    "        reg_lambda=reg_lambda\n",
    "    )\n",
    "    \n",
    "    clf.fit(X_tr, y_train)\n",
    "    preds = clf.predict(X_va)\n",
    "\n",
    "    return f1_score(y_val, preds, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfb61d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-05 02:11:17,320] A new study created in memory with name: no-name-5c17cf07-685d-49b9-84a4-41cb0e56ae6b\n",
      "[I 2025-07-05 02:12:11,449] Trial 0 finished with value: 0.5011973799369093 and parameters: {'max_df': 0.6872700594236812, 'min_df': 5, 'ngram_max': 2, 'max_features': 12000, 'n_estimators': 89, 'max_depth': 4, 'learning_rate': 0.026844247528777843, 'subsample': 0.9464704583099741, 'colsample_bytree': 0.8404460046972835, 'reg_alpha': 0.7080725777960455, 'reg_lambda': 0.020584494295802447}. Best is trial 0 with value: 0.5011973799369093.\n",
      "[I 2025-07-05 02:12:37,523] Trial 1 finished with value: 0.6589270442058881 and parameters: {'max_df': 0.9849549260809971, 'min_df': 5, 'ngram_max': 1, 'max_features': 4000, 'n_estimators': 96, 'max_depth': 5, 'learning_rate': 0.16217936517334897, 'subsample': 0.7727780074568463, 'colsample_bytree': 0.7164916560792167, 'reg_alpha': 0.6118528947223795, 'reg_lambda': 0.13949386065204183}. Best is trial 1 with value: 0.6589270442058881.\n",
      "[I 2025-07-05 02:13:27,191] Trial 2 finished with value: 0.6534782396401887 and parameters: {'max_df': 0.6460723242676091, 'min_df': 2, 'ngram_max': 1, 'max_features': 16000, 'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.18180022496999232, 'subsample': 0.6185801650879991, 'colsample_bytree': 0.8430179407605753, 'reg_alpha': 0.17052412368729153, 'reg_lambda': 0.06505159298527952}. Best is trial 1 with value: 0.6589270442058881.\n",
      "[I 2025-07-05 02:15:03,689] Trial 3 finished with value: 0.6287626205722696 and parameters: {'max_df': 0.9744427686266666, 'min_df': 5, 'ngram_max': 2, 'max_features': 7000, 'n_estimators': 74, 'max_depth': 8, 'learning_rate': 0.13764422318448438, 'subsample': 0.6488152939379115, 'colsample_bytree': 0.798070764044508, 'reg_alpha': 0.034388521115218396, 'reg_lambda': 0.9093204020787821}. Best is trial 1 with value: 0.6589270442058881.\n",
      "[I 2025-07-05 02:15:44,629] Trial 4 finished with value: 0.6766409061133816 and parameters: {'max_df': 0.6293899908000085, 'min_df': 4, 'ngram_max': 1, 'max_features': 11000, 'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.291179542051722, 'subsample': 0.9100531293444458, 'colsample_bytree': 0.9757995766256756, 'reg_alpha': 0.8948273504276488, 'reg_lambda': 0.5978999788110851}. Best is trial 4 with value: 0.6766409061133816.\n",
      "[I 2025-07-05 02:16:23,368] Trial 5 finished with value: 0.6184997845694772 and parameters: {'max_df': 0.9609371175115584, 'min_df': 1, 'ngram_max': 1, 'max_features': 1000, 'n_estimators': 131, 'max_depth': 6, 'learning_rate': 0.08869121921442981, 'subsample': 0.9314950036607718, 'colsample_bytree': 0.7427013306774357, 'reg_alpha': 0.28093450968738076, 'reg_lambda': 0.5426960831582485}. Best is trial 4 with value: 0.6766409061133816.\n",
      "[I 2025-07-05 02:17:24,629] Trial 6 finished with value: 0.5160200579115851 and parameters: {'max_df': 0.5704621124873813, 'min_df': 5, 'ngram_max': 1, 'max_features': 20000, 'n_estimators': 243, 'max_depth': 4, 'learning_rate': 0.011601413965844696, 'subsample': 0.9261845713819337, 'colsample_bytree': 0.8827429375390468, 'reg_alpha': 0.7290071680409873, 'reg_lambda': 0.7712703466859457}. Best is trial 4 with value: 0.6766409061133816.\n",
      "[I 2025-07-05 02:18:29,298] Trial 7 finished with value: 0.6114219556995658 and parameters: {'max_df': 0.5370223258670452, 'min_df': 2, 'ngram_max': 1, 'max_features': 18000, 'n_estimators': 206, 'max_depth': 5, 'learning_rate': 0.028431921582946856, 'subsample': 0.7243929286862649, 'colsample_bytree': 0.7300733288106989, 'reg_alpha': 0.7296061783380641, 'reg_lambda': 0.6375574713552131}. Best is trial 4 with value: 0.6766409061133816.\n",
      "[I 2025-07-05 02:20:17,426] Trial 8 finished with value: 0.635791499798553 and parameters: {'max_df': 0.9436063712881633, 'min_df': 3, 'ngram_max': 1, 'max_features': 15000, 'n_estimators': 240, 'max_depth': 7, 'learning_rate': 0.23358048218682267, 'subsample': 0.7975182385457563, 'colsample_bytree': 0.8090931317527976, 'reg_alpha': 0.42754101835854963, 'reg_lambda': 0.02541912674409519}. Best is trial 4 with value: 0.6766409061133816.\n"
     ]
    }
   ],
   "source": [
    "sampler = TPESampler(seed=42)\n",
    "study   = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Best macro-F1:\", study.best_value)\n",
    "print(\"Best hyperparameters:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3beb1c",
   "metadata": {},
   "source": [
    "- Applying Optimal Parameters for Retraining and Evaluation on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dae183",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = study.best_params\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        max_df       = best[\"max_df\"],\n",
    "        min_df       = best[\"min_df\"],\n",
    "        ngram_range  = (1, best[\"ngram_max\"]),\n",
    "        max_features = best[\"max_features\"],\n",
    "    )),\n",
    "    (\"clf\", XGBClassifier(\n",
    "        objective          = \"multi:softmax\",\n",
    "        num_class          = 3,\n",
    "        eval_metric        = \"mlogloss\",\n",
    "        random_state       = 42,\n",
    "        n_estimators       = best[\"n_estimators\"],\n",
    "        max_depth          = best[\"max_depth\"],\n",
    "        learning_rate      = best[\"learning_rate\"],\n",
    "        subsample          = best[\"subsample\"],\n",
    "        colsample_bytree   = best[\"colsample_bytree\"]\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f659d9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(train_texts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93adcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(test_df[\"text\"].astype(str))\n",
    "print(classification_report(test_df[\"sentiment_id\"],y_pred,target_names=[\"Negative\", \"Neutral\", \"Positive\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c5357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix \n",
    "cm = confusion_matrix(test_df[\"sentiment_id\"], y_pred)\n",
    "labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm, cmap=\"Blues\")        \n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)  \n",
    "ax.set_xticks(np.arange(len(labels)))\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_yticks(np.arange(len(labels)))\n",
    "ax.set_yticklabels(labels)\n",
    "ax.set_xlabel(\"Predicted Label\")\n",
    "ax.set_ylabel(\"True Label\")\n",
    "ax.set_title(\"Confusion Matrix for XGB (TD-IDF1\")\n",
    "\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9651fbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pipeline, \"xgb_tfidf_experiment1.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
